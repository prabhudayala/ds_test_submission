{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9eebb654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import pipeline\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder, Binarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from xgboost import XGBClassifier, XGBRFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ca94ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Training/X_train.csv')\n",
    "y = pd.read_csv('Training/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c472a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33050, 44)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b665497",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['C6'] = X['C6'].apply(lambda x: 0 if x==False else 1)\n",
    "X['C8'] = X['C8'].apply(lambda x: 0 if x==False else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b83ddd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:,1:]\n",
    "y = y['Dependent_Variable']\n",
    "X_numerical = X.iloc[:,8:]\n",
    "numerical_columns= list(X_numerical.columns)\n",
    "X_categorical = X.iloc[:,:8]\n",
    "categorical_columns= list(X_categorical.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77ec8b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fa7e3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1917683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21094361",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feature = numerical_columns.copy()\n",
    "all_feature.extend(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c3f87cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a116dfa",
   "metadata": {},
   "source": [
    "### Using all featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d760502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\tensorflow_2_6\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "          ('poly', PolynomialFeatures(degree=1)),\n",
    "        ('std', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "          ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "column_combine = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_columns),\n",
    "        (\"cat\", cat_pipeline, categorical_columns),\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline(steps=[('data_pre_process', column_combine), ('model', LogisticRegression())])\n",
    "history = full_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32f35c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC is:  0.7705835206700378\n",
      "Test AUC is:  0.7587575880165814\n"
     ]
    }
   ],
   "source": [
    "y_train_proba = full_pipeline.predict_proba(X_train)\n",
    "y_test_proba = full_pipeline.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_proba[:,1], pos_label=1)\n",
    "train_auc =  auc(fpr, tpr)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba[:,1], pos_label=1)\n",
    "test_auc =  auc(fpr, tpr)\n",
    "print(\"Train AUC is: \",train_auc)\n",
    "print(\"Test AUC is: \",test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a8d4b",
   "metadata": {},
   "source": [
    "### Try selected features from EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dbdfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns_from_EDA = list(set(['N1',\n",
    " 'N2',\n",
    " 'N3',\n",
    " 'N4',\n",
    " 'N5',\n",
    " 'N6',\n",
    " 'N7',\n",
    " 'N8',\n",
    " 'N9',\n",
    " 'N10',\n",
    " 'N10.1',\n",
    " 'N11',\n",
    " 'N12',\n",
    " 'N14',\n",
    " 'N15',\n",
    " 'N16',\n",
    " 'N17',\n",
    " 'N18',\n",
    " 'N19',\n",
    " 'N20',\n",
    " 'N21',\n",
    " 'N22',\n",
    " 'N23',\n",
    " 'N24',\n",
    " 'N25',\n",
    " 'N26',\n",
    " 'N27',\n",
    " 'N28',\n",
    " 'N29',\n",
    " 'N30',\n",
    " 'N31',\n",
    " 'N32',\n",
    " 'N33',\n",
    " 'N34',\n",
    " 'N35']) - set(['N26','N27','N28','N29','N6','N3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2933a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns_from_EDA = list(set(['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8'])-set(['C3','C6','C8']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4329ed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\tensorflow_2_6\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "          ('poly', PolynomialFeatures(degree=1)),\n",
    "        ('std', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "          ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "column_combine = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_columns_from_EDA),\n",
    "        (\"cat\", cat_pipeline, categorical_columns_from_EDA),\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline(steps=[('data_pre_process', column_combine), ('model', LogisticRegression())])\n",
    "history = full_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff9810f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC is:  0.760554242730847\n",
      "Test AUC is:  0.7526109677027044\n"
     ]
    }
   ],
   "source": [
    "y_train_proba = full_pipeline.predict_proba(X_train)\n",
    "y_test_proba = full_pipeline.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_proba[:,1], pos_label=1)\n",
    "train_auc =  auc(fpr, tpr)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba[:,1], pos_label=1)\n",
    "test_auc =  auc(fpr, tpr)\n",
    "print(\"Train AUC is: \",train_auc)\n",
    "print(\"Test AUC is: \",test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc09aedc",
   "metadata": {},
   "source": [
    "### Try outlier removal from EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cad98e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "    ])\n",
    "\n",
    "column_combine = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_columns),\n",
    "        (\"cat\", cat_pipeline, categorical_columns),\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline(steps=[('data_pre_process', column_combine)])\n",
    "TEMP = full_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb53cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMP = full_pipeline.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3d38fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22143, 43)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(TEMP,columns=all_feature)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b03cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "clf = LocalOutlierFactor(n_neighbors=20)\n",
    "clf.fit_predict(data)\n",
    "negative_outlier_factor = clf.negative_outlier_factor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bf9dd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9544700853825031"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_outlier_factor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de7cebe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.116913085035561"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_outlier_factor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f66bd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22143, 44)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_outlier_removed = pd.concat([data.reset_index(),y_train.reset_index()],axis=1)\n",
    "data_outlier_removed = data_outlier_removed.drop(columns=['index'])\n",
    "data_outlier_removed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "570d574a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of data in train is:  0.004516099896134662\n"
     ]
    }
   ],
   "source": [
    "data_outlier_removed['is_outlier'] = negative_outlier_factor\n",
    "data_outlier_removed = data_outlier_removed[data_outlier_removed['is_outlier']>-7]\n",
    "print(\"Loss of data in train is: \", (1-(data_outlier_removed.shape[0]/data.shape[0]))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eba3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_outlier_removed = data_outlier_removed.drop(columns=['is_outlier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dd94c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_out = data_outlier_removed['Dependent_Variable']\n",
    "X_train_out = data_outlier_removed.drop(columns=['Dependent_Variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc466987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\tensorflow_2_6\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "          ('poly', PolynomialFeatures(degree=1)),\n",
    "        ('std', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "          ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "column_combine = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_columns),\n",
    "        (\"cat\", cat_pipeline, categorical_columns),\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline(steps=[('data_pre_process', column_combine), ('model', LogisticRegression())])\n",
    "history = full_pipeline.fit(X_train_out,y_train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf67a53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>...</th>\n",
       "      <th>N34</th>\n",
       "      <th>N35</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.225387</td>\n",
       "      <td>0.304623</td>\n",
       "      <td>1.792958</td>\n",
       "      <td>1.070056</td>\n",
       "      <td>1.235184</td>\n",
       "      <td>1.792958</td>\n",
       "      <td>1.824841</td>\n",
       "      <td>1.747241</td>\n",
       "      <td>-0.185805</td>\n",
       "      <td>-0.340505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162440</td>\n",
       "      <td>0.468606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.434033</td>\n",
       "      <td>-0.376256</td>\n",
       "      <td>1.792958</td>\n",
       "      <td>-0.088833</td>\n",
       "      <td>-0.060146</td>\n",
       "      <td>1.792958</td>\n",
       "      <td>0.344433</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>-0.482090</td>\n",
       "      <td>-0.340505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440927</td>\n",
       "      <td>-0.351626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.443781</td>\n",
       "      <td>-0.514953</td>\n",
       "      <td>-0.622620</td>\n",
       "      <td>-0.088833</td>\n",
       "      <td>-0.060146</td>\n",
       "      <td>-0.622620</td>\n",
       "      <td>-0.572010</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>-0.404702</td>\n",
       "      <td>-0.340505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573440</td>\n",
       "      <td>-0.351626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.126491</td>\n",
       "      <td>-0.666260</td>\n",
       "      <td>-1.347293</td>\n",
       "      <td>1.649500</td>\n",
       "      <td>1.882849</td>\n",
       "      <td>-1.347293</td>\n",
       "      <td>1.190381</td>\n",
       "      <td>1.527054</td>\n",
       "      <td>0.457621</td>\n",
       "      <td>-0.340505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.292057</td>\n",
       "      <td>0.878722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.711797</td>\n",
       "      <td>0.783759</td>\n",
       "      <td>-0.864178</td>\n",
       "      <td>-0.475129</td>\n",
       "      <td>-0.276034</td>\n",
       "      <td>-0.864178</td>\n",
       "      <td>-1.065479</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>0.095003</td>\n",
       "      <td>-0.340505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.924966</td>\n",
       "      <td>-0.488331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         N1        N2        N3        N4        N5        N6        N7  \\\n",
       "0 -1.225387  0.304623  1.792958  1.070056  1.235184  1.792958  1.824841   \n",
       "1 -1.434033 -0.376256  1.792958 -0.088833 -0.060146  1.792958  0.344433   \n",
       "2  0.443781 -0.514953 -0.622620 -0.088833 -0.060146 -0.622620 -0.572010   \n",
       "3  0.126491 -0.666260 -1.347293  1.649500  1.882849 -1.347293  1.190381   \n",
       "4 -0.711797  0.783759 -0.864178 -0.475129 -0.276034 -0.864178 -1.065479   \n",
       "\n",
       "         N8        N9       N10  ...       N34       N35   C1    C2    C3  \\\n",
       "0  1.747241 -0.185805 -0.340505  ... -0.162440  0.468606  1.0  15.0  26.0   \n",
       "1 -0.014250 -0.482090 -0.340505  ... -0.440927 -0.351626  1.0   1.0   2.0   \n",
       "2 -0.014250 -0.404702 -0.340505  ... -0.573440 -0.351626  1.0   0.0  14.0   \n",
       "3  1.527054  0.457621 -0.340505  ... -0.292057  0.878722  1.0   0.0  15.0   \n",
       "4 -0.014250  0.095003 -0.340505  ... -0.924966 -0.488331  1.0   7.0  48.0   \n",
       "\n",
       "     C4   C5   C6   C7   C8  \n",
       "0   1.0  1.0  1.0  2.0  1.0  \n",
       "1  41.0  2.0  1.0  2.0  1.0  \n",
       "2   1.0  2.0  0.0  4.0  1.0  \n",
       "3   6.0  2.0  1.0  2.0  1.0  \n",
       "4  17.0  2.0  0.0  4.0  1.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71bf43b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_out = X_test.copy()\n",
    "X_test_out.columns = X_train_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a04f4a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC is:  0.7705523807871115\n",
      "Test AUC is:  0.530392414708756\n"
     ]
    }
   ],
   "source": [
    "y_train_proba = full_pipeline.predict_proba(X_train_out)\n",
    "y_test_proba = full_pipeline.predict_proba(X_test_out)\n",
    "fpr, tpr, thresholds = roc_curve(y_train_out, y_train_proba[:,1], pos_label=1)\n",
    "train_auc =  auc(fpr, tpr)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba[:,1], pos_label=1)\n",
    "test_auc =  auc(fpr, tpr)\n",
    "print(\"Train AUC is: \",train_auc)\n",
    "print(\"Test AUC is: \",test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ed28d8",
   "metadata": {},
   "source": [
    "**`Removing outlier performs good on train but test AUC is less. I am planning to keep all the points.`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59332b2",
   "metadata": {},
   "source": [
    "### Try different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389541f3",
   "metadata": {},
   "source": [
    "`As EDA did not help much lets try different models on all data. I will do that in next notebook with hyper parameter tuning`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cbc50b",
   "metadata": {},
   "source": [
    "#### 1. Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca8fff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "          ('poly', PolynomialFeatures(degree=1)),\n",
    "        ('std', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "          ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "column_combine = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_columns),\n",
    "        (\"cat\", cat_pipeline, categorical_columns),\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline(steps=[('data_pre_process', column_combine), ('model', RandomForestClassifier())])\n",
    "history = full_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9545d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC is:  1.0\n",
      "Test AUC is:  0.7667201021828219\n"
     ]
    }
   ],
   "source": [
    "y_train_proba = full_pipeline.predict_proba(X_train)\n",
    "y_test_proba = full_pipeline.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_proba[:,1], pos_label=1)\n",
    "train_auc =  auc(fpr, tpr)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba[:,1], pos_label=1)\n",
    "test_auc =  auc(fpr, tpr)\n",
    "print(\"Train AUC is: \",train_auc)\n",
    "print(\"Test AUC is: \",test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72f9caa",
   "metadata": {},
   "source": [
    "### Try PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112c372",
   "metadata": {},
   "source": [
    "#### With only numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14704040",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "          ('poly', PolynomialFeatures(degree=1)),\n",
    "        ('std', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "          ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "column_combine = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_columns),\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline(steps=[('data_pre_process', column_combine)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1f088cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PCA = full_pipeline.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62206cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_PCA = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5c50562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_pca = pca.fit_transform(X_train_PCA)\n",
    "X_test_pca = pca.transform(X_test_PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "926730d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22143, 43)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fddee1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22143, 30)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86000d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ca93f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC is:  0.7426755704114802\n",
      "Test AUC is:  0.7410426983171278\n"
     ]
    }
   ],
   "source": [
    "y_train_proba = model_lr.predict_proba(X_train_pca)\n",
    "y_test_proba = model_lr.predict_proba(X_test_pca)\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_proba[:,1], pos_label=1)\n",
    "train_auc =  auc(fpr, tpr)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba[:,1], pos_label=1)\n",
    "test_auc =  auc(fpr, tpr)\n",
    "print(\"Train AUC is: \",train_auc)\n",
    "print(\"Test AUC is: \",test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af838fcb",
   "metadata": {},
   "source": [
    "#### With numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1bd0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "          ('poly', PolynomialFeatures(degree=1)),\n",
    "        ('std', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "          ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "column_combine = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_columns),\n",
    "        (\"cat\", cat_pipeline, categorical_columns),\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline(steps=[('data_pre_process', column_combine)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7e9bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_PCA = full_pipeline.fit_transform(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a78929e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_PCA = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ca26c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22143x200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 952149 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45f7c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99)\n",
    "X_train_pca = pca.fit_transform(X_train_PCA.toarray())\n",
    "X_test_pca = pca.transform(X_test_PCA.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db235174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22143, 200)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_PCA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b30379d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22143, 94)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75d466e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6ad6944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC is:  0.7641632616088638\n",
      "Test AUC is:  0.7551516752632945\n"
     ]
    }
   ],
   "source": [
    "y_train_proba = model_lr.predict_proba(X_train_pca)\n",
    "y_test_proba = model_lr.predict_proba(X_test_pca)\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_proba[:,1], pos_label=1)\n",
    "train_auc =  auc(fpr, tpr)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba[:,1], pos_label=1)\n",
    "test_auc =  auc(fpr, tpr)\n",
    "print(\"Train AUC is: \",train_auc)\n",
    "print(\"Test AUC is: \",test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e7cec",
   "metadata": {},
   "source": [
    "### Try XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d315878",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba2d8104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda3\\envs\\tensorflow_2_6\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:58:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "          ('poly', PolynomialFeatures(degree=1)),\n",
    "        ('std', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "          ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ])\n",
    "\n",
    "column_combine = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_columns),\n",
    "        (\"cat\", cat_pipeline, categorical_columns),\n",
    "    ])\n",
    "\n",
    "full_pipeline = Pipeline(steps=[('data_pre_process', column_combine), ('model', XGBClassifier())])\n",
    "history = full_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "636f4913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC is:  0.9413591619902961\n",
      "Test AUC is:  0.7584976766892917\n"
     ]
    }
   ],
   "source": [
    "y_train_proba = full_pipeline.predict_proba(X_train)\n",
    "y_test_proba = full_pipeline.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_train_proba[:,1], pos_label=1)\n",
    "train_auc =  auc(fpr, tpr)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba[:,1], pos_label=1)\n",
    "test_auc =  auc(fpr, tpr)\n",
    "print(\"Train AUC is: \",train_auc)\n",
    "print(\"Test AUC is: \",test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
